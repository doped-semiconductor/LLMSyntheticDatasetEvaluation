{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "  \n",
    "class TextClassifier(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        return self.bert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "  \n",
    "class Utils:\n",
    "    @staticmethod    \n",
    "    def load_data(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.dropna()\n",
    "        return df['text'].tolist(), df['y'].tolist()\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_data_loader(texts, labels, tokenizer, max_len, batch_size):\n",
    "        dataset = TextDataset(texts, labels, tokenizer, max_len)\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_base_model_path(task):\n",
    "        return '../models/baseline/'+task+'-base-model.pth'\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mini_test_data(task):\n",
    "        return \"..\\\\data\\\\orig\\\\processed\\\\test\\\\\"+task+\"-data.csv\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def eval_model(model, data_loader, device):\n",
    "        model = model.eval()\n",
    "        predictions, true_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in data_loader:\n",
    "                input_ids = data['input_ids'].to(device)\n",
    "                attention_mask = data['attention_mask'].to(device)\n",
    "                labels = data['labels'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                _, preds = torch.max(logits, dim=1)\n",
    "                \n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        return accuracy_score(true_labels, predictions), classification_report(true_labels, predictions)\n",
    "\n",
    "tasks = {\n",
    "    'news':{\n",
    "        'model_base':Utils.get_base_model_path('news'),\n",
    "        'test_data':Utils.get_mini_test_data('news'),\n",
    "        'MAX_LEN':32,\n",
    "    },\n",
    "    'spam':{\n",
    "        'model_base':Utils.get_base_model_path('spam'),\n",
    "        'test_data':Utils.get_mini_test_data('spam'),\n",
    "        'MAX_LEN':48,\n",
    "    },\n",
    "    'sentiment':{\n",
    "        'model_base':Utils.get_base_model_path('sentiment'),\n",
    "        'test_data':Utils.get_mini_test_data('sentiment'),\n",
    "        'MAX_LEN':48,\n",
    "    }\n",
    "}\n",
    "\n",
    "class Config:\n",
    "    MODEL_NAME = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(Config.MODEL_NAME)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame({'type':['base','gpt-2','llama3','flan'],'news':[0,0,0,0],'spam':[0,0,0,0],'sentiment':[0,0,0,0]})\n",
    "df_out.set_index('type', inplace=True)\n",
    "predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news': {'model_base': '../models/baseline/news-base-model.pth',\n",
       "  'test_data': '..\\\\data\\\\orig\\\\processed\\\\test\\\\news-data.csv',\n",
       "  'MAX_LEN': 32},\n",
       " 'spam': {'model_base': '../models/baseline/spam-base-model.pth',\n",
       "  'test_data': '..\\\\data\\\\orig\\\\processed\\\\test\\\\spam-data.csv',\n",
       "  'MAX_LEN': 48},\n",
       " 'sentiment': {'model_base': '../models/baseline/sentiment-base-model.pth',\n",
       "  'test_data': '..\\\\data\\\\orig\\\\processed\\\\test\\\\sentiment-data.csv',\n",
       "  'MAX_LEN': 48}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\sreya\\AppData\\Local\\Temp\\ipykernel_3732\\3390788899.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(tasks[task][data_type]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreya\\AppData\\Local\\Temp\\ipykernel_3732\\3390788899.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.718' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_out.at['base',task] = predictions[task][0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>spam</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.956912</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           news      spam  sentiment\n",
       "type                                \n",
       "base   0.521739  0.956912      0.718\n",
       "gpt-2  0.000000  0.000000      0.000\n",
       "llm2   0.000000  0.000000      0.000\n",
       "llm3   0.000000  0.000000      0.000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type = 'model_base'\n",
    "for task in tasks:\n",
    "    if task in ['news','spam']:\n",
    "        continue\n",
    "    class Config:\n",
    "        MAX_LEN = tasks[task]['MAX_LEN']\n",
    "        BATCH_SIZE = 20\n",
    "        MODEL_NAME = 'bert-base-uncased'\n",
    "    test_texts, test_labels = Utils.load_data(tasks[task]['test_data'])\n",
    "    print(\"Len: \",len(test_texts))\n",
    "    test_data_loader = Utils.create_data_loader(test_texts, test_labels, tokenizer, Config.MAX_LEN, Config.BATCH_SIZE)\n",
    "    model = TextClassifier(model_name=Config.MODEL_NAME, num_labels=2)\n",
    "    model.load_state_dict(torch.load(tasks[task][data_type]))\n",
    "    predictions[task] = Utils.eval_model(model, test_data_loader, device)\n",
    "    print(predictions[task][0])\n",
    "    df_out.at['base',task] = predictions[task][0]\n",
    "    \n",
    "df_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>spam</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.956912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           news      spam  sentiment\n",
       "type                                \n",
       "base   0.521739  0.956912          0\n",
       "gpt-2  0.000000  0.000000          0\n",
       "llm2   0.000000  0.000000          0\n",
       "llm3   0.000000  0.000000          0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
