{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model: GPT-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_req_rows(type):\n",
    "    file = '..\\\\data\\\\orig\\\\processed\\\\train\\\\news-data.csv'\n",
    "    if(type=='sentiment'):\n",
    "        file = '..\\\\data\\\\orig\\\\processed\\\\train\\\\sentiment-data-mini.csv'\n",
    "    elif(type=='spam'):\n",
    "        file = '..\\\\data\\\\orig\\\\processed\\\\train\\\\spam-data-mini.csv'\n",
    "    df = pd.read_csv(file)\n",
    "    return int(df.shape[0]/2)\n",
    "\n",
    "prompts = {\n",
    "    'spam': 'Text message with advertisement or offer',\n",
    "    'non_spam':'Text message from a friend or family says',\n",
    "    'real_news':'Recently published political news title',\n",
    "    'fake_news':'Fake political news title',\n",
    "    'happy_tweet':'Tweet as a happy person',\n",
    "    'sad_tweet': 'Tweet as a sad person'\n",
    "}\n",
    "\n",
    "zsl_tasks = [\n",
    "    {\n",
    "        'name':'news',\n",
    "        'rows_per_category': count_req_rows('news'),\n",
    "        'query': prompts['fake_news'],\n",
    "        'non_query': prompts['real_news'],\n",
    "        'print_count':10\n",
    "    },\n",
    "    {\n",
    "        'name':'spam',\n",
    "        'rows_per_category': count_req_rows('spam'),\n",
    "        'query': prompts['spam'],\n",
    "        'non_query': prompts['non_spam'],\n",
    "        'print_count':100\n",
    "    },    \n",
    "    {\n",
    "        'name':'sentiment',\n",
    "        'rows_per_category': count_req_rows('sentiment'),\n",
    "        'query': prompts['happy_tweet'],\n",
    "        'non_query': prompts['sad_tweet'],\n",
    "        'print_count':250\n",
    "    }\n",
    "]\n",
    "\n",
    "def generate_text_from_prompt(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=50, num_return_sequences=1, do_sample=True, top_k=0)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text message from a friend or family says that one of the missing items found near the Vancouver wildfires is alcohol.\\n\\nThe bride quickly removed her spectacles and agreed to send it across the border with a question.\\n\\nBut firefighters found the bag'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "# generate_text_from_prompt(prompt=zsl_tasks[0]['non_query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ZSP - Data Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Starting task:  spam\n",
      "NQ-Progress: 0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 420 440 460 480 500 520 540 560 580 600 \n",
      "2. Generated non query df\n",
      "Q-Progress: 0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 420 440 460 480 500 520 540 560 580 600 \n",
      "3. Generated query df\n",
      "4. Saving df\n",
      "5. Ending task:  spam\n",
      "1. Starting task:  sentiment\n",
      "NQ-Progress: 0 250 500 750 1000 1250 1500 1750 2000 2250 \n",
      "2. Generated non query df\n",
      "Q-Progress: 0 250 500 750 1000 1250 1500 1750 2000 2250 \n",
      "3. Generated query df\n",
      "4. Saving df\n",
      "5. Ending task:  sentiment\n"
     ]
    }
   ],
   "source": [
    "df_main = pd.DataFrame()\n",
    "for task in zsl_tasks:\n",
    "    df_1 = pd.DataFrame(columns=['text'])\n",
    "    df_2 = pd.DataFrame(columns=['text'])\n",
    "\n",
    "    print(\"1. Starting task: \", task['name'])\n",
    "    print(\"NQ-Progress:\", end=' ')\n",
    "    for _ in range(task['rows_per_category']):\n",
    "        gen_text = generate_text_from_prompt(prompt = task['non_query'])\n",
    "        df_2.loc[len(df_2)] = gen_text\n",
    "        if _%task['print_count'] == 0:\n",
    "            print(_, end=' ')\n",
    "            df_2.to_csv(\"../data/syn/mid/auto-\" + task['name'] + \"-nquery-data.csv\", index=False)\n",
    "    \n",
    "\n",
    "    print(\"\\n2. Generated non query df\")\n",
    "    print(\"Q-Progress:\", end=' ')\n",
    "    for _ in range(task['rows_per_category']):\n",
    "        gen_text = generate_text_from_prompt(prompt = task['query'])\n",
    "        df_1.loc[len(df_1)] = gen_text\n",
    "        if _%task['print_count'] == 0:\n",
    "            print(_, end=' ')\n",
    "            df_1.to_csv(\"../data/syn/mid/auto-\" + task['name'] + \"-query-data.csv\", index=False)\n",
    "    \n",
    "    print(\"\\n3. Generated query df\")\n",
    "\n",
    "    df_1['y']=1\n",
    "    df_2['y']=0\n",
    "\n",
    "    print(\"4. Saving df\")\n",
    "\n",
    "    df = pd.concat([df_1, df_2], ignore_index=True)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df_main = df\n",
    "    df.to_csv(\"../data/syn/zsl/auto-\" + task['name'] + \"-data.csv\", index=False)\n",
    "\n",
    "    print(\"5. Ending task: \", task['name'])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
