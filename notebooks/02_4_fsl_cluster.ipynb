{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data from CSV using pandas\n",
    "def load_data_from_df(data, y=3):\n",
    "    if y==3:\n",
    "        return data\n",
    "    elif y!=3:\n",
    "        data = data[data['y']==y][\"text\"]\n",
    "    texts = data.tolist()  #data.dropna().tolist()  # Ensure there are no NaN values\n",
    "    return texts\n",
    "\n",
    "def load_data(task):\n",
    "    if(task == \"news\"):\n",
    "        df_1 = pd.read_csv(\"..\\\\data\\\\orig\\\\main\\\\news\\\\BuzzFeed_fake_news_content.csv\")\n",
    "        df_2 = pd.read_csv(\"..\\\\data\\\\orig\\\\main\\\\news\\\\BuzzFeed_real_news_content.csv\")\n",
    "\n",
    "        df_1['text'] = df_1['title'] + ' ' + df_1['text']\n",
    "        df_2['text'] = df_2['title'] + ' ' + df_2['text']\n",
    "\n",
    "        df_1 = df_1[['text']]\n",
    "        df_2 = df_2[['text']]\n",
    "\n",
    "        df_1['y'] = 1\n",
    "        df_2['y'] = 0\n",
    "\n",
    "        df1_train, df1_test = train_test_split(df_1, random_state=42)\n",
    "        df2_train, df2_test = train_test_split(df_2, random_state=36)\n",
    "\n",
    "        df1 = pd.concat([df1_train, df2_train], ignore_index=True)\n",
    "        df1 = df1.sample(frac=1).reset_index(drop=True)\n",
    "        df1.dropna(inplace=True)        \n",
    "        return df1\n",
    "    \n",
    "    if(task == \"spam\"):\n",
    "        df = pd.read_csv(\"../data/orig/main/spam/data.csv\", encoding='ISO-8859-1')\n",
    "        df = df[[\"v1\", \"v2\"]]\n",
    "        df[\"v1\"] = df[\"v1\"].apply(lambda x: 1 if x==\"spam\" else 0)\n",
    "        df.rename(columns={\"v1\":\"y\",\"v2\":\"text\"}, inplace=True)\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        df1, df2 = train_test_split(df, test_size=0.2, random_state=65)\n",
    "        df1.dropna(inplace=True)\n",
    "        df1 = pd.concat([df1[df1['y']==1], df1[df1['y']==0].sample(n=602)], ignore_index=True)\n",
    "        return df1\n",
    "    df = pd.read_csv(\"../data/orig/main/sentiment/data.csv\", encoding='latin-1', header=None)\n",
    "    df = df[[0,5]]\n",
    "    df.rename(columns={0:'y',5:'text'}, inplace=True)\n",
    "    df['y'] = df['y'].apply(lambda x: 1 if x==4 else 0)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df1, df2  = train_test_split(df, random_state=46, test_size=0.3)\n",
    "    df1.dropna(inplace=True)\n",
    "    n = 2500\n",
    "    df1 = pd.concat([df1[df1['y']==1].sample(n=n), df1[df1['y']==0].sample(n=n)], ignore_index=True)\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 2: Convert the text data to a TF-IDF matrix\n",
    "def tfidf_matrix(texts):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf = vectorizer.fit_transform(texts)\n",
    "    return tfidf\n",
    "\n",
    "# Step 3: Determine optimal clusters using the elbow method and silhouette score\n",
    "def find_optimal_clusters(tfidf_matrix, max_k):\n",
    "    inertias = []\n",
    "    silhouette_scores = []\n",
    "    idx = 0\n",
    "    max_sil = 0\n",
    "    main_model = None\n",
    "    \n",
    "    for k in range(2, max_k + 1):\n",
    "        model = KMeans(n_clusters=k)\n",
    "        model.fit(tfidf_matrix)\n",
    "        \n",
    "        inertia = model.inertia_  # Sum of squared distances to nearest cluster center\n",
    "        inertias.append(inertia)\n",
    "        \n",
    "        # Calculate the silhouette score\n",
    "        silhouette_avg = silhouette_score(tfidf_matrix, model.labels_)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "        if(silhouette_avg>max_sil):\n",
    "            idx = k\n",
    "            max_sil = silhouette_avg\n",
    "            main_model = model\n",
    "        \n",
    "        # print(f\"Cluster: {k}, Inertia: {inertia:.5f}, Silhouette Score: {silhouette_avg:.5f}\")\n",
    "\n",
    "    return inertias, silhouette_scores, idx, max_sil, main_model\n",
    "\n",
    "# Step 4: Plot the elbow graph and silhouette scores\n",
    "def plot_metrics(inertias, silhouette_scores, max_k):\n",
    "    ks = range(2, max_k + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot Inertia (Elbow Method)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(ks, inertias, marker='o')\n",
    "    plt.xlabel(\"Number of Clusters (k)\")\n",
    "    plt.ylabel(\"Inertia\")\n",
    "    plt.title(\"Elbow Method for Optimal k\")\n",
    "\n",
    "    # Plot Silhouette Score\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(ks, silhouette_scores, marker='o', color='green')\n",
    "    plt.xlabel(\"Number of Clusters (k)\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.title(\"Silhouette Score for Optimal k\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def get_mini_train_data(task):\n",
    "    return \"../data/orig/processed/train/\"+task+\"-data-mini.csv\"\n",
    "\n",
    "def find_cluster_groupings(task, max_k):\n",
    "    csv_file = get_mini_train_data(task) # Replace with your CSV file path\n",
    "\n",
    "    texts = load_data(task)\n",
    "    texts = texts[texts['y']==0][\"text\"]\n",
    "    texts = texts.tolist() \n",
    "    tfidf = tfidf_matrix(texts)\n",
    "    inertias, silhouette_scores, idx, max_sil, model0 = find_optimal_clusters(tfidf, max_k)\n",
    "    print(f\"Task: {task}, Max at {idx}, Silhouette Score: \", max_sil)\n",
    "    # plot_metrics(inertias, silhouette_scores, max_k)\n",
    "\n",
    "    texts = load_data(task)    \n",
    "    texts = texts[texts['y']==1][\"text\"]\n",
    "    texts = texts.tolist() \n",
    "    tfidf = tfidf_matrix(texts)\n",
    "    inertias, silhouette_scores, idx, max_sil, model1 = find_optimal_clusters(tfidf, max_k)\n",
    "    print(f\"Task: {task}, Max at {idx}, Silhouette Score: \", max_sil)\n",
    "    # plot_metrics(inertias, silhouette_scores, max_k)\n",
    "    return model0, model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    'news':{\n",
    "        'max_k':3\n",
    "    },\n",
    "    'spam':{\n",
    "        'max_k':5\n",
    "    },\n",
    "    'sentiment':{\n",
    "        'max_k':7\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: news, Max at 3, Silhouette Score:  0.008976069687305396\n",
      "Task: news, Max at 3, Silhouette Score:  0.019413893294439644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreya\\AppData\\Local\\Temp\\ipykernel_1172\\2151047047.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df0['fsl_category'] = tasks[task]['model0'].fit_predict(tfidf_matrix(df0['text']))\n",
      "C:\\Users\\sreya\\AppData\\Local\\Temp\\ipykernel_1172\\2151047047.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['fsl_category'] = tasks[task]['model1'].fit_predict(tfidf_matrix(df1['text']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsl_category\n",
      "0    52\n",
      "1     8\n",
      "2     8\n",
      "Name: count, dtype: int64\n",
      "fsl_category\n",
      "1    31\n",
      "2    23\n",
      "0    14\n",
      "Name: count, dtype: int64\n",
      "news\n",
      "Task: spam, Max at 4, Silhouette Score:  0.008337666591837307\n",
      "Task: spam, Max at 5, Silhouette Score:  0.014071664507477865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreya\\AppData\\Local\\Temp\\ipykernel_1172\\2151047047.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df0['fsl_category'] = tasks[task]['model0'].fit_predict(tfidf_matrix(df0['text']))\n",
      "C:\\Users\\sreya\\AppData\\Local\\Temp\\ipykernel_1172\\2151047047.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['fsl_category'] = tasks[task]['model1'].fit_predict(tfidf_matrix(df1['text']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsl_category\n",
      "3    447\n",
      "2     69\n",
      "1     62\n",
      "0     24\n",
      "Name: count, dtype: int64\n",
      "fsl_category\n",
      "2    203\n",
      "1    190\n",
      "4    102\n",
      "3     80\n",
      "0     31\n",
      "Name: count, dtype: int64\n",
      "spam\n",
      "Task: sentiment, Max at 7, Silhouette Score:  0.006558214956034779\n",
      "Task: sentiment, Max at 7, Silhouette Score:  0.0077828788292062315\n",
      "fsl_category\n",
      "0    1761\n",
      "2     187\n",
      "1     180\n",
      "3     115\n",
      "5     101\n",
      "4      88\n",
      "6      68\n",
      "Name: count, dtype: int64\n",
      "fsl_category\n",
      "2    1766\n",
      "0     164\n",
      "3     134\n",
      "1     131\n",
      "5     125\n",
      "6     123\n",
      "4      57\n",
      "Name: count, dtype: int64\n",
      "sentiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreya\\AppData\\Local\\Temp\\ipykernel_1172\\2151047047.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df0['fsl_category'] = tasks[task]['model0'].fit_predict(tfidf_matrix(df0['text']))\n",
      "C:\\Users\\sreya\\AppData\\Local\\Temp\\ipykernel_1172\\2151047047.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['fsl_category'] = tasks[task]['model1'].fit_predict(tfidf_matrix(df1['text']))\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    model0, model1 = find_cluster_groupings(task, tasks[task]['max_k'])\n",
    "    tasks[task]['model0'] = model0\n",
    "    tasks[task]['model1'] = model1\n",
    "\n",
    "    df = load_data(task)\n",
    "    df0 = df[df['y']==0]\n",
    "    df0['fsl_category'] = tasks[task]['model0'].fit_predict(tfidf_matrix(df0['text']))\n",
    "    print(df0['fsl_category'].value_counts())\n",
    "    df1 = df[df['y']==1]\n",
    "    df1['fsl_category'] = tasks[task]['model1'].fit_predict(tfidf_matrix(df1['text']))\n",
    "    print(df1['fsl_category'].value_counts())\n",
    "    print(task)\n",
    "    df = pd.concat([df1, df0], ignore_index=True)  \n",
    "    df.to_csv('../data/syn/mid/fsl-cat-'+task+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
