{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT2 = \"gpt2\"\n",
    "FLAN = \"flan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name) \n",
    "\n",
    "def generate_text_from_prompt(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=49)\n",
    "    \n",
    "    outputs = model.generate(**inputs, max_length=50, num_return_sequences=1, do_sample=True, top_k=0)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "def generate_text_from_prompt(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=49)\n",
    "    \n",
    "    outputs = model.generate(**inputs, max_length=50, num_return_sequences=1, do_sample=True, top_k=0)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fsl_data(task):\n",
    "    return pd.read_csv(\"../data/syn/mid/fsl-cat-\"+task+\".csv\")\n",
    "\n",
    "tasks = {\n",
    "    'news':{\n",
    "        'loop':10\n",
    "    },\n",
    "    'spam':{\n",
    "        'loop':100\n",
    "    },\n",
    "    'sentiment':{\n",
    "        'loop':250\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = FLAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_fsl_data(task)\n",
    "# prompt = df[df['fsl_category']==0].sample(n=1)\n",
    "# prompt['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: news\n",
      "df0 rows: 68, nun: 3\n",
      "\n",
      "Value: 0, Count: 52\n",
      "Prompt: Debate Commission ST\n",
      "0 10 20 30 40 50 \n",
      "Finished Cat:  0\n",
      "\n",
      "Value: 1, Count: 8\n",
      "Prompt: KISS Bassist Gene Si\n",
      "0 \n",
      "Finished Cat:  1\n",
      "\n",
      "Value: 2, Count: 8\n",
      "Prompt: Charlotte Police REV\n",
      "0 \n",
      "Finished Cat:  2\n",
      "Finished df0\n",
      "Start: news\n",
      "df1 rows: 68, nun: 3\n",
      "\n",
      "Value: 0, Count: 52\n",
      "Prompt: U.S. mistakenly gran\n",
      "0 10 20 30 40 50 \n",
      "Finished Cat:  0\n",
      "\n",
      "Value: 1, Count: 8\n",
      "Prompt: â€œPublic School Force\n",
      "0 \n",
      "Finished Cat:  1\n",
      "\n",
      "Value: 2, Count: 8\n",
      "Prompt: Young Girl's Emotion\n",
      "0 \n",
      "Finished Cat:  2\n",
      "Finished df1\n",
      "Start: spam\n",
      "df0 rows: 602, nun: 4\n",
      "\n",
      "Value: 3, Count: 447\n",
      "Prompt: Have a good trip. Wa\n",
      "0 100 200 300 400 \n",
      "Finished Cat:  3\n",
      "\n",
      "Value: 2, Count: 69\n",
      "Prompt: Correct. So how was \n",
      "0 \n",
      "Finished Cat:  2\n",
      "\n",
      "Value: 1, Count: 62\n",
      "Prompt: Ahhh. Work. I vaguel\n",
      "0 \n",
      "Finished Cat:  1\n",
      "\n",
      "Value: 0, Count: 24\n",
      "Prompt: R we going with the \n",
      "0 \n",
      "Finished Cat:  0\n",
      "Finished df0\n",
      "Start: spam\n",
      "df1 rows: 602, nun: 4\n",
      "\n",
      "Value: 3, Count: 447\n",
      "Prompt: If you r @ home then\n",
      "0 100 200 300 400 \n",
      "Finished Cat:  3\n",
      "\n",
      "Value: 2, Count: 69\n",
      "Prompt: Havent planning to b\n",
      "0 \n",
      "Finished Cat:  2\n",
      "\n",
      "Value: 1, Count: 62\n",
      "Prompt: Say this slowly.? GO\n",
      "0 \n",
      "Finished Cat:  1\n",
      "\n",
      "Value: 0, Count: 24\n",
      "Prompt: Tell my  bad charact\n",
      "0 \n",
      "Finished Cat:  0\n",
      "Finished df1\n",
      "Start: sentiment\n",
      "df0 rows: 2500, nun: 7\n",
      "\n",
      "Value: 0, Count: 1761\n",
      "Prompt: Bus broke down on th\n",
      "0 250 500 750 1000 1250 1500 1750 \n",
      "Finished Cat:  0\n",
      "\n",
      "Value: 2, Count: 187\n",
      "Prompt: @Dannymcfly I SAW A \n",
      "0 \n",
      "Finished Cat:  2\n",
      "\n",
      "Value: 1, Count: 180\n",
      "Prompt: Back to San Diego to\n",
      "0 \n",
      "Finished Cat:  1\n",
      "\n",
      "Value: 3, Count: 115\n",
      "Prompt: I'm on my way to wor\n",
      "0 \n",
      "Finished Cat:  3\n",
      "\n",
      "Value: 5, Count: 101\n",
      "Prompt: @PrncessBri i had to\n",
      "0 \n",
      "Finished Cat:  5\n",
      "\n",
      "Value: 4, Count: 88\n",
      "Prompt: Loving my new car ev\n",
      "0 \n",
      "Finished Cat:  4\n",
      "\n",
      "Value: 6, Count: 68\n",
      "Prompt: xboxtweet not workin\n",
      "0 \n",
      "Finished Cat:  6\n",
      "Finished df0\n",
      "Start: sentiment\n",
      "df1 rows: 2500, nun: 7\n",
      "\n",
      "Value: 0, Count: 1761\n",
      "Prompt: still has a sore thr\n",
      "0 250 500 750 1000 1250 1500 1750 \n",
      "Finished Cat:  0\n",
      "\n",
      "Value: 2, Count: 187\n",
      "Prompt: I don't like the way\n",
      "0 \n",
      "Finished Cat:  2\n",
      "\n",
      "Value: 1, Count: 180\n",
      "Prompt: on the phone with Ar\n",
      "0 \n",
      "Finished Cat:  1\n",
      "\n",
      "Value: 3, Count: 115\n",
      "Prompt: Getting ready for an\n",
      "0 \n",
      "Finished Cat:  3\n",
      "\n",
      "Value: 5, Count: 101\n",
      "Prompt: @GeezusHaberdash wha\n",
      "0 \n",
      "Finished Cat:  5\n",
      "\n",
      "Value: 4, Count: 88\n",
      "Prompt: Nanna's bakery sound\n",
      "0 \n",
      "Finished Cat:  4\n",
      "\n",
      "Value: 6, Count: 68\n",
      "Prompt: ohhh i'm bummed. the\n",
      "0 \n",
      "Finished Cat:  6\n",
      "Finished df1\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    df = get_fsl_data(task)\n",
    "    df0_n = pd.DataFrame(columns=['text'])\n",
    "    df1_n = pd.DataFrame(columns=['text'])\n",
    "    #cat 0\n",
    "    df0 = df[df['y']==0]\n",
    "    print(f\"Start: {task}\")\n",
    "    print(f\"df0 rows: {df0.shape[0]}, nun: {df0['fsl_category'].nunique()}\")\n",
    "    for value, count in df0['fsl_category'].value_counts().items(): \n",
    "        print(f\"\\nValue: {value}, Count: {count}\")\n",
    "        prompt = df0[df0['fsl_category']==value].sample(n=1)\n",
    "        prompt = prompt['text'].values[0]\n",
    "        print(f\"Prompt: {prompt[:20]}\")\n",
    "        for _ in range(count):\n",
    "            text = generate_text_from_prompt(prompt)\n",
    "            df0_n.loc[len(df0_n)] = text\n",
    "            if _%tasks[task]['loop']==0:\n",
    "                print(_, end=\" \")\n",
    "        print(f\"\\nFinished Cat: \", value)\n",
    "    df0_n['y']=0\n",
    "    print(\"Finished df0\")\n",
    "\n",
    "    df1 = df[df['y']==0]\n",
    "    print(f\"Start: {task}\")\n",
    "    print(f\"df1 rows: {df1.shape[0]}, nun: {df1['fsl_category'].nunique()}\")\n",
    "    for value, count in df0['fsl_category'].value_counts().items(): \n",
    "        print(f\"\\nValue: {value}, Count: {count}\")\n",
    "        prompt = df1[df1['fsl_category']==value].sample(n=1)\n",
    "        prompt = prompt['text'].values[0]\n",
    "        print(f\"Prompt: {prompt[:20]}\")\n",
    "        for _ in range(count):\n",
    "            text = generate_text_from_prompt(prompt)\n",
    "            df1_n.loc[len(df1_n)] = text\n",
    "            if _%tasks[task]['loop']==0:\n",
    "                print(_, end=\" \")\n",
    "        print(f\"\\nFinished Cat: \", value)\n",
    "    df1_n['y']=1\n",
    "    print(\"Finished df1\")\n",
    "\n",
    "    df = pd.concat([df1_n, df0_n], ignore_index=True).sample(frac=1)\n",
    "    df.to_csv('../data/syn/'+LLM+'/fs/auto-'+task+'-fs.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
